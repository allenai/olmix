# DCLM baseline fit config
# Fits regression models against 127 DCLM swarm runs across 24 DataDelve domains

swarm:
  ratios: dclm_ratios.csv
  metrics: dclm_metrics.csv

priors:
  relative_sizes:
    adult_content: 0.015
    art_and_design: 0.035
    crime_and_law: 0.030
    education_and_jobs: 0.045
    electronics_and_hardware: 0.025
    entertainment: 0.080
    fashion_and_beauty: 0.020
    finance_and_business: 0.060
    food_and_dining: 0.025
    games: 0.030
    health: 0.050
    history_and_geography: 0.035
    home_and_hobbies: 0.030
    industrial: 0.015
    literature: 0.040
    politics: 0.045
    religion: 0.020
    science_math_and_technology: 0.070
    social_life: 0.060
    software: 0.050
    software_development: 0.060
    sports_and_fitness: 0.040
    transportation: 0.020
    travel_and_tourism: 0.030
  total_tokens: 3_000_000_000_000
  token_counts:
    adult_content: 45_000_000_000
    art_and_design: 105_000_000_000
    crime_and_law: 90_000_000_000
    education_and_jobs: 135_000_000_000
    electronics_and_hardware: 75_000_000_000
    entertainment: 240_000_000_000
    fashion_and_beauty: 60_000_000_000
    finance_and_business: 180_000_000_000
    food_and_dining: 75_000_000_000
    games: 90_000_000_000
    health: 150_000_000_000
    history_and_geography: 105_000_000_000
    home_and_hobbies: 90_000_000_000
    industrial: 45_000_000_000
    literature: 120_000_000_000
    politics: 135_000_000_000
    religion: 60_000_000_000
    science_math_and_technology: 210_000_000_000
    social_life: 180_000_000_000
    software: 150_000_000_000
    software_development: 180_000_000_000
    sports_and_fitness: 120_000_000_000
    transportation: 60_000_000_000
    travel_and_tourism: 90_000_000_000

eval:
  type: offline
  tasks:
    math:
      - "minerva_math_algebra::olmes"
      - "minerva_math_counting_and_probability::olmes"
      - "minerva_math_geometry::olmes"
      - "minerva_math_intermediate_algebra::olmes"
      - "minerva_math_number_theory::olmes"
      - "minerva_math_prealgebra::olmes"
      - "minerva_math_precalculus::olmes"
    code:
      - "codex_humaneval:3shot::none"
      - "mbpp:3shot::none"
      - "mt_mbpp_v2fix:bash"
      - "mt_mbpp_v2fix:c"
      - "mt_mbpp_v2fix:cpp"
      - "mt_mbpp_v2fix:csharp"
      - "mt_mbpp_v2fix:go"
      - "mt_mbpp_v2fix:haskell"
      - "mt_mbpp_v2fix:java"
      - "mt_mbpp_v2fix:javascript"
      - "mt_mbpp_v2fix:matlab"
      - "mt_mbpp_v2fix:php"
      - "mt_mbpp_v2fix:python"
      - "mt_mbpp_v2fix:r"
      - "mt_mbpp_v2fix:ruby"
      - "mt_mbpp_v2fix:rust"
      - "mt_mbpp_v2fix:scala"
      - "mt_mbpp_v2fix:swift"
      - "mt_mbpp_v2fix:typescript"
    qa:
      - "arc_challenge:rc::olmes"
      - "arc_easy:rc::olmes"
      - "basic_skills:rc::olmes"
      - "basic_skills_arithmetic:rc::olmes"
      - "basic_skills_coding:rc::olmes"
      - "basic_skills_common_knowledge:rc::olmes"
      - "basic_skills_logical_reasoning:rc::olmes"
      - "basic_skills_pattern:rc::olmes"
      - "basic_skills_string_operations:rc::olmes"
      - "coqa:rc::gen2mc"
      - "csqa:rc::olmes"
      - "drop:rc::gen2mc"
      - "hellaswag:rc::olmes"
      - "jeopardy:rc::gen2mc"
      - "lab_bench_dbqa"
      - "lab_bench_protocolqa"
      - "lambada"
      - "medmcqa:rc::none"
      - "medqa_en:rc::none"
      - "mmlu_abstract_algebra:rc::olmes"
      - "mmlu_anatomy:rc::olmes"
      - "mmlu_astronomy:rc::olmes"
      - "mmlu_business_ethics:rc::olmes"
      - "mmlu_clinical_knowledge:rc::olmes"
      - "mmlu_college_biology:rc::olmes"
      - "mmlu_college_chemistry:rc::olmes"
      - "mmlu_college_computer_science:rc::olmes"
      - "mmlu_college_mathematics:rc::olmes"
      - "mmlu_college_medicine:rc::olmes"
      - "mmlu_college_physics:rc::olmes"
      - "mmlu_computer_security:rc::olmes"
      - "mmlu_conceptual_physics:rc::olmes"
      - "mmlu_econometrics:rc::olmes"
      - "mmlu_electrical_engineering:rc::olmes"
      - "mmlu_elementary_mathematics:rc::olmes"
      - "mmlu_formal_logic:rc::olmes"
      - "mmlu_global_facts:rc::olmes"
      - "mmlu_high_school_biology:rc::olmes"
      - "mmlu_high_school_chemistry:rc::olmes"
      - "mmlu_high_school_computer_science:rc::olmes"
      - "mmlu_high_school_european_history:rc::olmes"
      - "mmlu_high_school_geography:rc::olmes"
      - "mmlu_high_school_government_and_politics:rc::olmes"
      - "mmlu_high_school_macroeconomics:rc::olmes"
      - "mmlu_high_school_mathematics:rc::olmes"
      - "mmlu_high_school_microeconomics:rc::olmes"
      - "mmlu_high_school_physics:rc::olmes"
      - "mmlu_high_school_psychology:rc::olmes"
      - "mmlu_high_school_statistics:rc::olmes"
      - "mmlu_high_school_us_history:rc::olmes"
      - "mmlu_high_school_world_history:rc::olmes"
      - "mmlu_human_aging:rc::olmes"
      - "mmlu_human_sexuality:rc::olmes"
      - "mmlu_international_law:rc::olmes"
      - "mmlu_jurisprudence:rc::olmes"
      - "mmlu_logical_fallacies:rc::olmes"
      - "mmlu_machine_learning:rc::olmes"
      - "mmlu_management:rc::olmes"
      - "mmlu_marketing:rc::olmes"
      - "mmlu_medical_genetics:rc::olmes"
      - "mmlu_miscellaneous:rc::olmes"
      - "mmlu_moral_disputes:rc::olmes"
      - "mmlu_moral_scenarios:rc::olmes"
      - "mmlu_nutrition:rc::olmes"
      - "mmlu_philosophy:rc::olmes"
      - "mmlu_prehistory:rc::olmes"
      - "mmlu_professional_accounting:rc::olmes"
      - "mmlu_professional_law:rc::olmes"
      - "mmlu_professional_medicine:rc::olmes"
      - "mmlu_professional_psychology:rc::olmes"
      - "mmlu_public_relations:rc::olmes"
      - "mmlu_security_studies:rc::olmes"
      - "mmlu_sociology:rc::olmes"
      - "mmlu_us_foreign_policy:rc::olmes"
      - "mmlu_virology:rc::olmes"
      - "mmlu_world_religions:rc::olmes"
      - "naturalqs:rc::gen2mc"
      - "piqa:rc::olmes"
      - "qasper_yesno:rc::olmes"
      - "sciq:rc::olmo3"
      - "sciriff_yesno:rc::olmes"
      - "socialiqa:rc::olmes"
      - "squad:rc::gen2mc"
      - "winogrande:rc::olmes"

regression:
  type: log_linear
  alpha: 1.0
  seed: 0
  n_test: 0
  train_split: [1.0]
  simulation_samples: 100000
  opt_avg_metric: true
  aggregate_task_families: true

proposer:
  type: exact
  temperature: null
  kl_reg: 0.1
  use_natural_kl: true
  fit_only: true
  make_worst_mix: false

constraints:
  enabled: false
  target_tokens: null
  repetition_factor: 5.0

filtering:
  keep_sources: []
  support_domains: []
  drop_metrics: []
  fixed_weight: {}
  obj_weights: {}
