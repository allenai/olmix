name: example-swarm-2

data:
  sources:
    - name: dclm
      weight: 0.7
      topics:
        - name: science_math_and_technology
          paths:
            - "s3://ai2-llm/preprocessed/dclm/baseline_topic_ft_lr05_ng2_n3M6_ova_20pct/allenai/dolma2-tokenizer/science_math_and_technology/**/*.npy"
        - name: software_development
          paths:
            - "s3://ai2-llm/preprocessed/dclm/baseline_topic_ft_lr05_ng2_n3M6_ova_20pct/allenai/dolma2-tokenizer/software_development/**/*.npy"
        - name: education_and_jobs
          paths:
            - "s3://ai2-llm/preprocessed/dclm/baseline_topic_ft_lr05_ng2_n3M6_ova_20pct/allenai/dolma2-tokenizer/education_and_jobs/**/*.npy"
    - name: wikipedia
      weight: 0.01
      paths:
        - "s3://ai2-llm/preprocessed/wikipedia-dolma-0823/allenai/dolma2-tokenizer/*.npy"
    - name: arxiv
      weight: 0.29
      paths:
        - "s3://ai2-llm/preprocessed/proof-pile-2/v0_decontaminated-0625_tokenized/arxiv/train/allenai/dolma2-tokenizer/*.npy"

priors:
  relative_sizes:
    arxiv: 0.13859324268101414
    dclm:education_and_jobs: 0.13466673502770904
    dclm:science_math_and_technology: 0.5479947162541395
    dclm:software_development: 0.1548063887874921
    wikipedia: 0.023938917249645256
  token_counts:
    arxiv: 21377485731
    dclm:education_and_jobs: 20771836713
    dclm:science_math_and_technology: 84526121193
    dclm:software_development: 23878302458
    wikipedia: 3692487830

swarm:
  seed: 42
  variants: 4
  mix_temperature: 1.0
  min_strength: 0.1
  max_strength: 5.0
  minimum_weight: 0.002
  manual_topic_prior:
    dclm:education_and_jobs: 0.1
    dclm:science_math_and_technology: 0.1
    dclm:software_development: 0.8

max_tokens: 140000000  # e.g. 20 * 14M params * 0.5 chinchilla multiple
